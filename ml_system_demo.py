#!/usr/bin/env python3
"""
Complete ML System Demo

Demonstrates the full automated ML system for Polymarket including:
- Database storage and retrieval
- ML tools and agent capabilities
- Complete ML pipelines
- Experiment tracking and reporting
"""

import sys
import os
from datetime import datetime

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from agents.automl.ml_database import MLDatabase
from agents.automl.ml_agent import create_ml_agent


def demonstrate_database_operations():
    """Demonstrate database operations."""
    print("ğŸ—„ï¸ ML Database Operations Demo")
    print("=" * 35)

    db = MLDatabase()

    # Create a sample experiment
    experiment_id = db.create_experiment(
        name="Demo Experiment",
        description="Demonstrating ML database capabilities"
    )
    print(f"âœ… Created experiment: {experiment_id}")

    # Save a sample model
    model_info = {
        'name': 'Demo MarketPredictor',
        'model_type': 'MarketPredictor',
        'algorithm': 'RandomForest',
        'hyperparameters': {'n_estimators': 100, 'max_depth': 10},
        'feature_columns': ['volume', 'yes_price', 'category'],
        'training_samples': 1000,
        'training_start_time': datetime.now().isoformat(),
        'training_end_time': datetime.now().isoformat()
    }

    model_id = db.save_model(experiment_id, model_info)
    print(f"âœ… Saved model: {model_id}")

    # Save sample metrics
    metrics = {
        'accuracy': 0.75,
        'precision': 0.72,
        'recall': 0.78,
        'f1': 0.75,
        'roc_auc': 0.82
    }

    db.save_model_metrics(model_id, metrics)
    print(f"âœ… Saved metrics for model: {metrics}")

    # Save sample predictions
    predictions = [
        {
            'market_id': 'demo_market_1',
            'predicted_probability': 0.65,
            'actual_outcome': 1,
            'confidence': 0.8,
            'recommended_bet': 'YES',
            'position_size': 0.05,
            'expected_value': 0.025
        },
        {
            'market_id': 'demo_market_2',
            'predicted_probability': 0.45,
            'actual_outcome': 0,
            'confidence': 0.7,
            'recommended_bet': 'NO',
            'position_size': 0.03,
            'expected_value': 0.015
        }
    ]

    db.save_predictions(model_id, predictions)
    print(f"âœ… Saved {len(predictions)} predictions")

    # Save evaluation results
    evaluation_config = {'evaluation_type': 'backtest', 'test_period_days': 30}
    evaluation_results = {
        'total_trades': 50,
        'win_rate': 0.68,
        'avg_return_per_trade': 0.025,
        'sharpe_ratio': 1.8,
        'max_drawdown': 0.15
    }

    db.save_evaluation(model_id, 'backtest', evaluation_config, evaluation_results, 45.2)
    print("âœ… Saved evaluation results")
    # Get experiment results
    results = db.get_experiment_results(experiment_id)
    if results:
        print("âœ… Retrieved experiment results:"        print(f"   â€¢ Models: {len(results['models'])}")
        print(f"   â€¢ Datasets: {len(results['datasets'])}")

    # Show database stats
    stats = db.get_database_stats()
    print("\\nğŸ“Š Database Statistics:")
    print(f"   â€¢ Experiments: {stats.get('experiments_count', 0)}")
    print(f"   â€¢ Models: {stats.get('models_count', 0)}")
    print(f"   â€¢ Predictions: {stats.get('predictions_count', 0)}")
    print(".1f"
    return experiment_id, model_id


def demonstrate_ml_agent_workflows():
    """Demonstrate ML agent workflow capabilities."""
    print("\\nğŸ¤– ML Agent Workflows Demo")
    print("=" * 32)

    agent = create_ml_agent()

    # Example workflows to demonstrate
    workflows = [
        "Check the quality of available market data",
        "Train a MarketPredictor model on recent data",
        "Evaluate the model's performance using backtesting"
    ]

    results = []

    for i, workflow in enumerate(workflows, 1):
        print(f"\\nğŸ¯ Workflow {i}: {workflow}")
        print("-" * 50)

        try:
            result = agent.run_ml_workflow(workflow)
            results.append(result)

            if result.get('status') == 'success':
                print("âœ… Completed successfully")
                if 'parsed_info' in result and result['parsed_info']:
                    print("ğŸ“‹ Key results:")
                    for key, value in result['parsed_info'].items():
                        print(f"   â€¢ {key}: {value}")
            else:
                print(f"âŒ Failed: {result.get('error', 'Unknown error')}")

        except Exception as e:
            print(f"âŒ Error: {e}")
            results.append({'status': 'error', 'error': str(e)})

    print(f"\\nğŸ“Š Agent Workflow Summary:")
    print(f"   â€¢ Workflows executed: {len(workflows)}")
    print(f"   â€¢ Successful: {sum(1 for r in results if r.get('status') == 'success')}")
    print(f"   â€¢ Failed: {sum(1 for r in results if r.get('status') != 'success')}")

    return results


def demonstrate_ml_tools():
    """Demonstrate individual ML tools."""
    print("\\nğŸ”§ ML Tools Demo")
    print("=" * 20)

    from agents.automl.ml_tools import (
        data_ingestion_tool,
        data_quality_tool,
        model_training_tool,
        model_evaluation_tool,
        prediction_tool
    )

    tools = [
        ("Data Ingestion", data_ingestion_tool, {"days_back": 30, "min_volume": 1000}),
        ("Data Quality Check", data_quality_tool, {"dataset_info": "demo dataset"}),
        ("Model Training", model_training_tool, {
            "model_type": "MarketPredictor",
            "experiment_name": "Tool Demo",
            "hyperparameters": {"n_estimators": 50}
        })
    ]

    results = []

    for tool_name, tool, params in tools:
        print(f"ğŸ› ï¸ Testing {tool_name}...")
        try:
            # Note: In practice, these would be called through the agent
            # This is just a demonstration of tool availability
            print(f"   âœ… {tool_name} tool is available")
            print(f"   ğŸ“ Description: {tool.description[:100]}...")
            results.append({'tool': tool_name, 'status': 'available'})

        except Exception as e:
            print(f"   âŒ {tool_name} failed: {e}")
            results.append({'tool': tool_name, 'status': 'error', 'error': str(e)})

    print(f"\\nğŸ”§ Tools Status: {sum(1 for r in results if r['status'] == 'available')}/{len(tools)} available")
    return results


def demonstrate_reporting():
    """Demonstrate reporting capabilities."""
    print("\\nğŸ“‹ ML Reporting Demo")
    print("=" * 23)

    agent = create_ml_agent()
    report = agent.create_ml_report()

    print("ğŸ“„ Generated ML Report:")
    print("=" * 30)

    # Show first few lines of report
    lines = report.split('\n')
    for line in lines[:20]:  # Show first 20 lines
        print(line)

    if len(lines) > 20:
        print(f"... ({len(lines) - 20} more lines)")

    print("\\nğŸ“Š Report Sections:")
    sections = [line for line in lines if line.startswith('##')]
    for section in sections:
        print(f"   â€¢ {section[3:]}")

    return report


def demonstrate_system_integration():
    """Demonstrate how all components work together."""
    print("\\nğŸ”— System Integration Demo")
    print("=" * 30)

    print("ğŸš€ Complete ML Pipeline Integration:")
    print()
    print("1. ğŸ“Š Data Ingestion")
    print("   â†’ Polymarket API â†’ Data cleaning â†’ Database storage")
    print()
    print("2. ğŸ”§ Data Quality Validation")
    print("   â†’ Statistical checks â†’ Outlier detection â†’ Feature engineering")
    print()
    print("3. ğŸ¤– ML Agent & Tools")
    print("   â†’ Intelligent workflows â†’ Automated model training â†’ Evaluation")
    print()
    print("4. ğŸ—„ï¸ Database Operations")
    print("   â†’ Experiment tracking â†’ Model storage â†’ Performance metrics")
    print()
    print("5. ğŸ“ˆ Reporting & Monitoring")
    print("   â†’ Automated reports â†’ Performance tracking â†’ Alert system")
    print()
    print("6. ğŸš€ Production Deployment")
    print("   â†’ Model serving â†’ Prediction APIs â†’ Continuous learning")
    print()

    print("âœ¨ Key Integration Points:")
    print("   â€¢ Agent uses tools for ML operations")
    print("   â€¢ Tools store results in database")
    print("   â€¢ Database provides data for reporting")
    print("   â€¢ Reports inform agent decisions")
    print("   â€¢ Continuous feedback loop for improvement")


def show_cli_usage():
    """Show CLI usage examples."""
    print("\\nğŸš€ CLI Usage Examples")
    print("=" * 25)

    examples = [
        ("Run ML workflow", "python ml_agent_cli.py workflow 'Train a market predictor model'"),
        ("Check database status", "python ml_agent_cli.py status"),
        ("Generate ML report", "python ml_agent_cli.py report --save-report"),
        ("Optimize hyperparameters", "python ml_agent_cli.py optimize MarketPredictor"),
        ("Create trading strategy", "python ml_agent_cli.py strategy model_123 --risk-tolerance 0.05")
    ]

    for desc, command in examples:
        print(f"ğŸ“ {desc}:")
        print(f"   {command}")
        print()


def main():
    """Main demonstration."""
    try:
        print("ğŸ¯ Complete ML System Demo for Polymarket")
        print("=" * 50)

        # Demonstrate database operations
        experiment_id, model_id = demonstrate_database_operations()

        # Demonstrate ML tools
        tool_results = demonstrate_ml_tools()

        # Demonstrate agent workflows
        workflow_results = demonstrate_ml_agent_workflows()

        # Demonstrate reporting
        report = demonstrate_reporting()

        # Show system integration
        demonstrate_system_integration()

        # Show CLI usage
        show_cli_usage()

        print("\\nğŸ‰ ML System Demo Complete!")
        print("\\nğŸ† System Capabilities Demonstrated:")
        print("   âœ… Database storage and retrieval")
        print("   âœ… ML tools for automated operations")
        print("   âœ… Intelligent agent workflows")
        print("   âœ… Experiment tracking and reporting")
        print("   âœ… Complete ML pipeline integration")
        print("   âœ… Production-ready architecture")

        print("\\nğŸš€ Ready for Production ML Operations!")
        print("\\nğŸ’¡ Next Steps:")
        print("1. Run: python ml_agent_cli.py status (check system health)")
        print("2. Train: python ml_agent_cli.py workflow 'Train models on recent data'")
        print("3. Deploy: Use trained models for live predictions")
        print("4. Monitor: python ml_agent_cli.py report (track performance)")

    except Exception as e:
        print(f"\\nâŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
