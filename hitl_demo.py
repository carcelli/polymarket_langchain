#!/usr/bin/env python3
"""
Human-in-the-Loop (HITL) Demo for Polymarket Deep Agents

This script demonstrates advanced human approval workflows:
- Interrupt handling for sensitive operations
- Multiple tool call approvals
- Tool argument editing capabilities
- Risk-based decision controls
- Interactive trading sessions

Run with: python hitl_demo.py
"""

import os
import uuid
from agents.deep_research_agent import (
    create_trading_agent_with_approval,
    handle_agent_interrupt,
    create_human_decisions,
    resume_agent_with_decisions,
    interactive_trading_session
)

def demo_basic_interrupt_handling():
    """Demonstrate basic interrupt detection and handling."""
    print("ğŸ”„ BASIC INTERRUPT HANDLING DEMO")
    print("=" * 50)

    if not (os.getenv("ANTHROPIC_API_KEY") and os.getenv("TAVILY_API_KEY")):
        print("âŒ API keys required for HITL demos")
        return

    # Create agent with trading approval
    agent = create_trading_agent_with_approval()
    thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}

    market_question = "Will Ethereum reach $10,000 by 2026?"

    print(f"ğŸ“Š Testing interrupt handling for: {market_question}")

    try:
        # Trigger a trade proposal that requires approval
        result = agent.invoke({
            "messages": [{
                "role": "user",
                "content": f"Analyze this market and if you find a good opportunity, execute a trade: {market_question}"
            }]
        }, config=config)

        # Check for interrupts
        needs_approval, interrupt_info = handle_agent_interrupt(result, config)

        if needs_approval:
            print("âœ… Interrupt detected!")
            print(f"Thread ID: {interrupt_info['thread_id']}")

            action_requests = interrupt_info["action_requests"]
            print(f"Pending actions: {len(action_requests)}")

            for i, action in enumerate(action_requests, 1):
                print(f"{i}. {action['name']}: {action['args']}")

        else:
            print("â„¹ï¸  No interrupts - agent completed without requiring approval")
            print(f"Result: {result['messages'][-1].content[:200]}...")

    except Exception as e:
        print(f"âŒ Basic interrupt demo failed: {str(e)}")


def demo_multiple_tool_approvals():
    """Demonstrate handling multiple tool calls requiring approval."""
    print("\nğŸ“‹ MULTIPLE TOOL APPROVALS DEMO")
    print("=" * 50)

    if not (os.getenv("ANTHROPIC_API_KEY") and os.getenv("TAVILY_API_KEY")):
        print("âŒ API keys required for multiple approvals demo")
        return

    agent = create_trading_agent_with_approval()
    thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}

    print("ğŸ¯ Testing multiple simultaneous approvals")
    print("Agent will attempt multiple trading operations...")

    try:
        # Trigger multiple trade operations
        result = agent.invoke({
            "messages": [{
                "role": "user",
                "content": "Execute multiple trades: a market buy for YES and a limit sell for NO on Bitcoin market"
            }]
        }, config=config)

        needs_approval, interrupt_info = handle_agent_interrupt(result, config)

        if needs_approval:
            action_requests = interrupt_info["action_requests"]
            review_configs = interrupt_info["review_configs"]

            print(f"âœ… {len(action_requests)} actions require approval:")
            print()

            # Display all pending actions
            for i, action in enumerate(action_requests, 1):
                config = review_configs[action["name"]]
                print(f"{i}. ğŸ”§ {action['name']}")
                print(f"   ğŸ“ Args: {action['args']}")
                print(f"   âœ… Allowed: {config['allowed_decisions']}")
                print()

            # Simulate user decisions for each action
            print("ğŸ¤– Simulated user decisions:")
            user_decisions = [
                {"type": "approve"} if i % 2 == 0 else {"type": "reject"}
                for i in range(len(action_requests))
            ]

            for i, decision in enumerate(user_decisions, 1):
                action_name = action_requests[i-1]["name"]
                print(f"   {i}. {action_name}: {decision['type']}")

            # Create properly formatted decisions
            decisions = create_human_decisions(action_requests, review_configs, user_decisions)
            print(f"\nğŸ“¤ Formatted decisions: {decisions}")

            # Resume execution
            final_result = resume_agent_with_decisions(agent, decisions, config)
            print("\nâœ… Multiple approvals processed successfully!")

        else:
            print("â„¹ï¸  No multiple approvals needed")

    except Exception as e:
        print(f"âŒ Multiple approvals demo failed: {str(e)}")


def demo_tool_argument_editing():
    """Demonstrate editing tool arguments before approval."""
    print("\nâœï¸  TOOL ARGUMENT EDITING DEMO")
    print("=" * 50)

    if not (os.getenv("ANTHROPIC_API_KEY") and os.getenv("TAVILY_API_KEY")):
        print("âŒ API keys required for editing demo")
        return

    agent = create_trading_agent_with_approval()
    thread_id = str(uuid.uuid4())
    config = {"configurable": {"thread_id": thread_id}}

    print("ğŸ¯ Testing tool argument editing capabilities")
    print("Agent will propose a trade, then we'll modify the parameters...")

    try:
        # Get agent to propose a trade
        result = agent.invoke({
            "messages": [{
                "role": "user",
                "content": "Propose a market buy order for YES on a crypto market"
            }]
        }, config=config)

        needs_approval, interrupt_info = handle_agent_interrupt(result, config)

        if needs_approval:
            action_requests = interrupt_info["action_requests"]

            if action_requests:
                action = action_requests[0]
                print(f"ğŸ“ Original action: {action['name']}")
                print(f"   Original args: {action['args']}")
                print()

                # Simulate user editing the trade parameters
                print("âœï¸  User edits the trade parameters:")
                edited_action = {
                    "name": action["name"],
                    "args": {
                        "token_id": "modified_token_id",
                        "amount": 500.0,  # Modified amount
                        "side": "BUY"
                    }
                }

                user_decisions = [{
                    "type": "edit",
                    "edited_action": edited_action
                }]

                print(f"   âœï¸  Modified amount: {edited_action['args']['amount']}")
                print(f"   ğŸ†” Modified token: {edited_action['args']['token_id']}")

                # Create and apply decisions
                review_configs = interrupt_info["review_configs"]
                decisions = create_human_decisions(action_requests, review_configs, user_decisions)

                final_result = resume_agent_with_decisions(agent, decisions, config)
                print("\nâœ… Trade executed with edited parameters!")

            else:
                print("â„¹ï¸  No editable actions proposed")

        else:
            print("â„¹ï¸  No editing opportunities")

    except Exception as e:
        print(f"âŒ Editing demo failed: {str(e)}")


def demo_risk_based_configuration():
    """Demonstrate different interrupt configurations for different risk levels."""
    print("\nâš ï¸  RISK-BASED CONFIGURATION DEMO")
    print("=" * 50)

    print("ğŸ›ï¸  Risk-Based Interrupt Strategies:")
    print()

    risk_configs = {
        "Conservative (High Safety)": {
            "trading": {"allowed_decisions": ["approve", "reject"]},  # No editing
            "research": {"allowed_decisions": ["approve", "reject"]},  # API calls need approval
            "description": "Maximum human oversight, minimal automation"
        },
        "Moderate (Balanced)": {
            "trading": {"allowed_decisions": ["approve", "edit", "reject"]},  # Full control
            "research": False,  # No interrupts for research
            "description": "Human oversight for trades, automation for research"
        },
        "Aggressive (High Automation)": {
            "trading": False,  # No interrupts
            "research": False,  # Full automation
            "description": "Minimal human intervention, high automation"
        }
    }

    for risk_level, config in risk_configs.items():
        print(f"ğŸ›¡ï¸  {risk_level}:")
        print(f"   {config['description']}")
        print(f"   Trading interrupts: {config['trading']}")
        print(f"   Research interrupts: {config['research']}")
        print()

    print("ğŸ’¡ Configuration Guidelines:")
    print("â€¢ High-risk operations: approve/edit/reject (full control)")
    print("â€¢ Medium-risk operations: approve/reject (no editing)")
    print("â€¢ Low-risk operations: False (no interrupts)")
    print("â€¢ Scale based on deployment environment and trust levels")


def demo_subagent_interrupts():
    """Demonstrate subagent-specific interrupt configurations."""
    print("\nğŸ­ SUBAGENT INTERRUPT CONFIGURATION DEMO")
    print("=" * 50)

    print("ğŸ‘¥ Subagent Interrupt Capabilities:")
    print()
    print("â€¢ Main agent can have different interrupt policies")
    print("â€¢ Subagents can override main agent settings")
    print("â€¢ trade_executor subagent requires approval for all trades")
    print("â€¢ market_researcher operates autonomously")
    print("â€¢ risk_analyzer focuses on calculations only")
    print()

    print("ğŸ”§ Configuration Example:")
    print("""
subagents = [
    {
        "name": "trade_executor",
        "interrupt_on": {
            "execute_market_order": {"allowed_decisions": ["approve", "edit", "reject"]},
            "execute_limit_order": {"allowed_decisions": ["approve", "reject"]},
        }
    }
]
""")

    print("ğŸ¯ Benefits:")
    print("â€¢ Granular control over different agent components")
    print("â€¢ Specialized safety policies for different operations")
    print("â€¢ Override main agent settings for specific subagents")


def demo_complete_workflow():
    """Demonstrate the complete human-in-the-loop workflow."""
    print("\nğŸš€ COMPLETE HITL WORKFLOW DEMO")
    print("=" * 50)

    print("ğŸ”„ Full Human-in-the-Loop Workflow:")
    print("1. Agent analyzes market and proposes actions")
    print("2. Sensitive operations trigger interrupts")
    print("3. Human reviews pending actions")
    print("4. Human makes approve/edit/reject decisions")
    print("5. Agent resumes with human decisions")
    print("6. Approved actions execute, rejected actions skip")
    print()

    # Run the interactive trading session demo
    print("ğŸ® Running Interactive Trading Session...")
    print("-" * 40)
    interactive_trading_session()


def main():
    """Run all human-in-the-loop demonstrations."""
    print("ğŸ‘¥ Human-in-the-Loop (HITL) Demo for Polymarket Deep Agents")
    print("Advanced interrupt handling and human approval workflows")

    # Check environment
    has_keys = bool(os.getenv("ANTHROPIC_API_KEY") and os.getenv("TAVILY_API_KEY"))
    if not has_keys:
        print("\nâš ï¸  Note: Full demos require API keys")
        print("Set: ANTHROPIC_API_KEY and TAVILY_API_KEY")

    print("\n" + "=" * 60)

    # Run demos
    demo_basic_interrupt_handling()
    demo_multiple_tool_approvals()
    demo_tool_argument_editing()
    demo_risk_based_configuration()
    demo_subagent_interrupts()
    demo_complete_workflow()

    print("\n" + "=" * 60)
    print("âœ… HUMAN-IN-THE-LOOP DEMO COMPLETE")
    print("=" * 60)

    print("""
ğŸ¯ HITL CAPABILITIES SUMMARY:

ğŸ”„ Interrupt Handling:
â€¢ Automatic pause on sensitive operations
â€¢ State persistence across approval cycles
â€¢ Resume execution with human decisions

ğŸ“‹ Multiple Approvals:
â€¢ Batch processing of multiple tool calls
â€¢ Ordered decision handling
â€¢ Consistent approval workflows

âœï¸ Argument Editing:
â€¢ Modify tool parameters before execution
â€¢ Full control over execution details
â€¢ Validation and safety checks

âš ï¸ Risk-Based Configuration:
â€¢ Conservative: approve/reject only (no editing)
â€¢ Moderate: approve/edit/reject (full control)
â€¢ Aggressive: no interrupts (full automation)

ğŸ‘¥ Subagent Interrupts:
â€¢ Per-subagent interrupt policies
â€¢ Override main agent settings
â€¢ Specialized safety controls

ğŸš€ Production Features:
â€¢ Checkpointer integration for state persistence
â€¢ Thread-safe operation with unique IDs
â€¢ Enterprise-grade approval workflows

ğŸ›ï¸ RESULT: Sophisticated human oversight capabilities
   enabling safe, controlled AI agent operation!
""")


if __name__ == "__main__":
    main()
